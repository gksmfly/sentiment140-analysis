### Sentiment140 데이터 분석 보고서

본 보고서는 **160만 개 규모의 Twitter 감정 데이터(Sentiment140)**를 기반으로  
감정 분포, 사용자 활동 패턴, 텍스트 특성 분석 및 LLM 기반 감정 분류 비교 결과를 정리한 문서입니다.

---

### 1. 분석 개요 / 문제 정의

회사 내부의 감정 분석 모델 정확도가 낮다는 문제가 제기되었고,  
CTO는 다음과 같은 질문에 답할 수 있는 데이터 분석을 요구했습니다:

- 긍정/부정 감정은 얼마나 존재하는가?  
- 특정 사용자나 특정 감정이 데이터를 왜곡하고 있지 않은가?  
- 긍정/부정 트윗은 어떤 언어적 특징을 가지는가?  
- 더 나은 모델을 만들기 위해 어떤 인사이트가 필요한가?  
- 최신 LLM(GPT)이 기존 라벨과 얼마나 일치하는가?

이를 해결하기 위해 다음 분석 작업을 수행했습니다:

- 데이터 구조 파악 및 라벨링 이해  
- 텍스트 전처리 파이프라인 구축 및 정제(cleaning)  
- 감정별 데이터 분포 분석  
- 사용자 활동 패턴 분석  
- 단어 빈도 기반 텍스트 특징 분석  
- GPT-4o-mini 모델을 활용한 감정 분류 정확도 비교  

---

### 2. 데이터 구조 설명

Sentiment140 CSV 데이터 구조는 다음과 같습니다:

| Column | Description |
|--------|-------------|
| 0 | polarity (0 = negative, 4 = positive) |
| 1 | tweet id |
| 2 | date |
| 3 | query (대부분 "NO_QUERY") |
| 4 | username |
| 5 | tweet text |

라벨링은 이미 제공되어 있으므로 추가적인 라벨링 작업은 필요하지 않습니다.

---

### 3. 데이터 전처리 과정 상세 설명 (Text Cleaning Pipeline)

트윗 텍스트는 비정형 데이터이기 때문에, 분석 전 다음과 같은 전처리를 수행했습니다:

1. **소문자 변환**  
2. **URL 제거** (`http...` 패턴 정규식 처리)  
3. **@사용자명 제거**  
4. **특수문자 제거** (영문자와 공백만 남김)  
5. **공백 기반 토큰화**  
6. **불용어(stopwords) 제거**  
7. **길이 2 이하 토큰 제거**  

#### 전처리 예시

#### 원본: 
```
“I LOVE Twitter!!! Check http://google.com @user”
```
#### 전처리 후:
```
[“love”, “twitter”, “check”]
```
이 과정은 텍스트 의미를 유지하면서 노이즈를 최소화하여  
정확한 패턴 분석이 가능하도록 돕습니다.

---

### 4. 감정별 데이터 분포 분석

실행 결과:
```
Negative (0): 456,259
Positive (4): 379,459
```

#### 주요 분석 내용

- 부정 트윗이 긍정 트윗보다 **약 20% 더 많음**
- 완전한 불균형 데이터는 아니지만, **부정 감정이 우세한 skew 존재**
- 실제 모델 훈련 시 class weight 조절 필요 가능성 있음

---

### 5. 사용자 활동 패턴 분석

상위 20명 사용자:
```
lost_dog: 274 tweets
tweetpet: 236 tweets
webwoke: 211 tweets
mcraddictal: 151 tweets
…
```

#### 분석 내용

- 일부 사용자가 매우 많은 트윗을 작성 → 데이터 편향 가능성  
- 많은 사용자가 bot 또는 자동화된 계정으로 추정됨  
- 특정 사용자 집단이 감정 분포를 왜곡하고 있을 가능성 존재  
- 감정별 사용자 경향 분석도 추가로 가능함  

---

### 6. 텍스트 특성 분석

### 6.1 긍정/부정 단어 빈도 분석 (Top Words)

#### 긍정 Top Words
```
love, good, thanks, lol, day, happy, great, …
```

#### 부정 Top Words
```
not, have, don, miss, sad, want, need, …
```
#### 차이점 요약

- 긍정 트윗: 감정 표현(love, happy), 감사(thanks), 웃음(lol) 등이 자주 등장  
- 부정 트윗: 결핍 표현(miss, want), 부정 단어(not, sad, don)이 뚜렷하게 나타남  
- 양쪽 단어 특성이 명확하게 구분됨 → 감정 분류 모델의 유용한 feature로 활용 가능

---

### 6.2 감정별 고유 단어 (Distinctive Words)

#### 긍정에서만 강하게 등장하는 단어
```
love, thanks, great, morning, happy, haha
```
#### 부정에서만 강하게 등장하는 단어
```
sad, miss, want, need, really, feel
```
#### 해석

- 긍정 단어는 칭찬/감사/일상 긍정톤이 뚜렷함  
- 부정 단어는 감정 결핍, 욕구, 우울감, 스트레스를 나타냄  
- 두 집합은 감정 분류 모델의 **symbolic feature** 로 활용 가치가 높음  

---

### 7. LLM 기반 분류 정확도 비교

GPT-4o-mini 모델로 200개 샘플을 분류한 결과:
LLM Accuracy = 0.77

#### 분석

- GPT가 Sentiment140 기존 라벨과 **77% 일치**  
- 트윗 텍스트가 2009년 데이터여서  
  최신 GPT 모델이 생소한 표현을 오해할 가능성이 있음  
- 이모티콘, 특수문자 제거 후 감정 정보가 일부 손실되었을 수도 있음  

---

### 8. 인사이트 및 모델 개선 제안

### ✔ 개선 가능한 모델 전략
- 감정 단어 사전 구축 → 규칙 기반 + ML 모델의 hybrid 구조 적용
- 사용자 편향 제거 (heavy users filtering)
- 부정 샘플 overweight 문제 해결을 위한 resampling 필요

### ✔ 데이터 품질 이슈
- 2009년 트윗이라 언어 패턴이 최신 경향과 다름  
- bot 계정 영향으로 데이터 왜곡 가능  
- 텍스트 정제 과정에서 이모티콘 감정 정보 손실

### ✔ 향후 확장 분석
- TF-IDF + Naive Bayes / Logistic Regression 모델 비교  
- 감정 사전 기반 lightweight classifier 제작  
- 최신 GPT 모델들과 성능 비교 실험

---

### 9. 결론

본 분석을 통해 다음과 같은 결론을 얻었습니다:

- Sentiment140 데이터는 부정 감정이 다소 우세한 skew를 보인다.  
- 특정 사용자 계정이 비정상적으로 많은 데이터를 생성하여 편향을 유발한다.  
- 긍정/부정 트윗은 단어 선택이 명확히 구분되는 특징이 있다.  
- LLM(GPT)은 약 77%의 정확도를 보이며 기존 라벨과 높은 일치도를 보인다.  

텍스트 전처리 → 감정 분포 분석 → 사용자 패턴 → 단어 특징 분석 → LLM 비교까지 이어지는  
전체 파이프라인은 감정 분석 모델 개선을 위한 중요한 기반을 제공한다.

---

### 10. AI 도구 활용 내역

본 프로젝트는 생성형 AI(GPT)를 “개발 보조 도구”로 활용하였으며,  
핵심 구현(데이터 파이프라인, 전처리, 분석 로직, LLM 평가 코드)은 직접 작성함 
AI는 아래와 같은 역할에서 참고용으로만 사용됨

#### 1) 프로젝트 구조 및 처리 전략 설계 참고
- 160만 행 규모의 Sentiment140 데이터를 효율적으로 다루기 위한 **Streaming 방식 선택** 과정에서 개념적 조언을 받음
- Kotlin 프로젝트 구조(main / reader / model / analysis / llm 모듈 분리) 설계 시 참고 자료로 활용
- 함수형 프로그래밍(map, filter, flatMap, groupingBy)을 활용한 **파이프라인 구조 설계**에서 가이드 참고

> 해당 구조를 바탕으로 실제 코드들은 직접 작성 및 리팩토링함

#### 2) 텍스트 전처리(Text Cleaning) 설계 참고
- NLP에서 일반적으로 수행하는 전처리 절차(소문자 변환, URL 제거, 멘션 제거, 불용어 제거 등)를 참고하여 기준을 정함
- 정규 표현식(regex) 작성 및 Kotlin 전처리 함수 구현(map/filter 조합)은 직접 수행

#### 3) OpenAI API 연동 방식 참고
- Kotlin에서 HTTP Client(OkHttp)로 API를 호출하는 방식과 JSON body 작성 형식을 참고
- OpenAILLM.kt 파일의 네트워크 처리, JSON 파싱, classify 함수 로직은 직접 구현
- Rate-limit(429) 오류를 해결하기 위해 **동시성 제한, 자동 재시도, 딜레이, fallback** 로직도 직접 구성

#### 4) LLM 기반 감정 분류 비교 기능 설계 보조
- GPT 모델 temperature=0 설정, seed 고정 등 “재현 가능한 평가 방식”에 대한 제안 참고
- 1000개 샘플을 GPT에게 재분류시키고 기존 라벨과의 **정확도(Accuracy)** 를 계산하는 전체 평가 로직(LLMComparison)은 직접 작성

#### 5) 문서(README, 분석 보고서, 발표자료) 구성 보조
- 보고서의 목차 구성, 흐름 정리, 설명 방식 개선 등 문서 품질 향상에 도움을 받음
- 실행 결과, 인사이트, 개선 방향 등 분석 내용은 직접 실행한 데이터를 기반으로 작성

#### 6) 개발 환경 오류 해결 참고
- OpenAI 환경 변수 설정 오류 해결
- Gradle 설정 문제 해결
- CSV 파싱 중 일부 행 손실 원인 분석 등 문제 해결 과정에서 AI를 참고용으로 활용
