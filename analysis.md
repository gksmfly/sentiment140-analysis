# Sentiment140 데이터 분석 보고서

본 보고서는 **160만 개 규모의 Twitter 감정 데이터(Sentiment140)**를 기반으로  
감정 분포, 사용자 활동 패턴, 텍스트 특성 분석 및 LLM 기반 감정 분류 비교 결과를 정리한 문서입니다.

---

# 1. 분석 개요 / 문제 정의

회사 내부의 감정 분석 모델 정확도가 낮다는 문제가 제기되었고,  
CTO는 다음과 같은 질문에 답할 수 있는 데이터 분석을 요구했습니다:

- 긍정/부정 감정은 얼마나 존재하는가?  
- 특정 사용자나 특정 감정이 데이터를 왜곡하고 있지 않은가?  
- 긍정/부정 트윗은 어떤 언어적 특징을 가지는가?  
- 더 나은 모델을 만들기 위해 어떤 인사이트가 필요한가?  
- 최신 LLM(GPT)이 기존 라벨과 얼마나 일치하는가?

이를 해결하기 위해 다음 분석 작업을 수행했습니다:

- 데이터 구조 파악 및 라벨링 이해  
- 텍스트 전처리 파이프라인 구축 및 정제(cleaning)  
- 감정별 데이터 분포 분석  
- 사용자 활동 패턴 분석  
- 단어 빈도 기반 텍스트 특징 분석  
- GPT-4o-mini 모델을 활용한 감정 분류 정확도 비교  

---

# 2. 데이터 구조 설명

Sentiment140 CSV 데이터 구조는 다음과 같습니다:

| Column | Description |
|--------|-------------|
| 0 | polarity (0 = negative, 4 = positive) |
| 1 | tweet id |
| 2 | date |
| 3 | query (대부분 "NO_QUERY") |
| 4 | username |
| 5 | tweet text |

라벨링은 이미 제공되어 있으므로 추가적인 라벨링 작업은 필요하지 않습니다.

---

# 3. 데이터 전처리 과정 상세 설명 (Text Cleaning Pipeline)

트윗 텍스트는 비정형 데이터이기 때문에, 분석 전 다음과 같은 전처리를 수행했습니다:

1. **소문자 변환**  
2. **URL 제거** (`http...` 패턴 정규식 처리)  
3. **@사용자명 제거**  
4. **특수문자 제거** (영문자와 공백만 남김)  
5. **공백 기반 토큰화**  
6. **불용어(stopwords) 제거**  
7. **길이 2 이하 토큰 제거**  

### 전처리 예시

#### 원본: 
```
“I LOVE Twitter!!! Check http://google.com @user”
```
#### 전처리 후:
```
[“love”, “twitter”, “check”]
```
이 과정은 텍스트 의미를 유지하면서 노이즈를 최소화하여  
정확한 패턴 분석이 가능하도록 돕습니다.

---

# 4. 감정별 데이터 분포 분석

실행 결과:
```
Negative (0): 456,259
Positive (4): 379,459
```

### 주요 분석 내용

- 부정 트윗이 긍정 트윗보다 **약 20% 더 많음**
- 완전한 불균형 데이터는 아니지만, **부정 감정이 우세한 skew 존재**
- 실제 모델 훈련 시 class weight 조절 필요 가능성 있음

---

# 5. 사용자 활동 패턴 분석

상위 20명 사용자:
```
lost_dog: 274 tweets
tweetpet: 236 tweets
webwoke: 211 tweets
mcraddictal: 151 tweets
…
```

### 분석 내용

- 일부 사용자가 매우 많은 트윗을 작성 → 데이터 편향 가능성  
- 많은 사용자가 bot 또는 자동화된 계정으로 추정됨  
- 특정 사용자 집단이 감정 분포를 왜곡하고 있을 가능성 존재  
- 감정별 사용자 경향 분석도 추가로 가능함  

---

# 6. 텍스트 특성 분석

## 6.1 긍정/부정 단어 빈도 분석 (Top Words)

### 긍정 Top Words
```
love, good, thanks, lol, day, happy, great, …
```

### 부정 Top Words
```
not, have, don, miss, sad, want, need, …
```
### 차이점 요약

- 긍정 트윗: 감정 표현(love, happy), 감사(thanks), 웃음(lol) 등이 자주 등장  
- 부정 트윗: 결핍 표현(miss, want), 부정 단어(not, sad, don)이 뚜렷하게 나타남  
- 양쪽 단어 특성이 명확하게 구분됨 → 감정 분류 모델의 유용한 feature로 활용 가능

---

## 6.2 감정별 고유 단어 (Distinctive Words)

### 긍정에서만 강하게 등장하는 단어
```
love, thanks, great, morning, happy, haha
```
### 부정에서만 강하게 등장하는 단어
```
sad, miss, want, need, really, feel
```
### 해석

- 긍정 단어는 칭찬/감사/일상 긍정톤이 뚜렷함  
- 부정 단어는 감정 결핍, 욕구, 우울감, 스트레스를 나타냄  
- 두 집합은 감정 분류 모델의 **symbolic feature** 로 활용 가치가 높음  

---

# 7. LLM 기반 분류 정확도 비교

GPT-4o-mini 모델로 200개 샘플을 분류한 결과:
LLM Accuracy = 0.77

### 분석

- GPT가 Sentiment140 기존 라벨과 **77% 일치**  
- 트윗 텍스트가 2009년 데이터여서  
  최신 GPT 모델이 생소한 표현을 오해할 가능성이 있음  
- 이모티콘, 특수문자 제거 후 감정 정보가 일부 손실되었을 수도 있음  

---

# 8. 인사이트 및 모델 개선 제안

## ✔ 개선 가능한 모델 전략
- 감정 단어 사전 구축 → 규칙 기반 + ML 모델의 hybrid 구조 적용
- 사용자 편향 제거 (heavy users filtering)
- 부정 샘플 overweight 문제 해결을 위한 resampling 필요

## ✔ 데이터 품질 이슈
- 2009년 트윗이라 언어 패턴이 최신 경향과 다름  
- bot 계정 영향으로 데이터 왜곡 가능  
- 텍스트 정제 과정에서 이모티콘 감정 정보 손실

## ✔ 향후 확장 분석
- TF-IDF + Naive Bayes / Logistic Regression 모델 비교  
- 감정 사전 기반 lightweight classifier 제작  
- 최신 GPT 모델들과 성능 비교 실험

---

# 9. 결론

본 분석을 통해 다음과 같은 결론을 얻었습니다:

- Sentiment140 데이터는 부정 감정이 다소 우세한 skew를 보인다.  
- 특정 사용자 계정이 비정상적으로 많은 데이터를 생성하여 편향을 유발한다.  
- 긍정/부정 트윗은 단어 선택이 명확히 구분되는 특징이 있다.  
- LLM(GPT)은 약 77%의 정확도를 보이며 기존 라벨과 높은 일치도를 보인다.  

텍스트 전처리 → 감정 분포 분석 → 사용자 패턴 → 단어 특징 분석 → LLM 비교까지 이어지는  
전체 파이프라인은 감정 분석 모델 개선을 위한 중요한 기반을 제공한다.
